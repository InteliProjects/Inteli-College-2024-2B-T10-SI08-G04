# Inteli - Instituto de Tecnologia e Lideran√ßa 

<p align="center">
<a href= "https://www.inteli.edu.br/"><img src="https://res.cloudinary.com/de8ca4say/image/upload/v1733257415/inteli_igd6f6.png" alt="Inteli - Instituto de Tecnologia e Lideran√ßa" border="0"></a>
</p>

# INTEGRA√á√ÉO, GERENCIAMENTO E AN√ÅLISE DE BIG DATA

## Quartzo

### Integrantes: 
- <a href="https://www.linkedin.com/in/celine-souza-1a38aa225?trk=blended-typeahead">Celine Souza</a>
- <a href="https://www.linkedin.com/in/joao-pedro-brandao/">Jo√£o Pedro Brand√£o de Moura</a>
- <a href="https://www.linkedin.com/in/matheusmeendes/">Matheus Ferreira Mendes</a>
- <a href="https://www.linkedin.com/in/paulooctaviodepaula?trk=blended-typeahead">Paulo Octavio De Paula</a>
- <a href="https://www.linkedin.com/in/rafaella-bianca-cavalcante/">Rafaella Bianca Cavalcante</a>
- <a href="https://www.linkedin.com/in/stefano-parente/">Stefano Tamer Parente</a>
- <a href="https://www.linkedin.com/in/yan-m-coutinho/">Yan Mendon√ßa Coutinho</a>

## üìù Descri√ß√£o

O projeto √© denominado "Desenvolvimento de um Pipeline de Big Data" e tem como objetivo auxiliar a Companhia Paulista de Trens Metropolitanos (CPTM) a processar grandes volumes de dados de forma eficiente, otimizando a tomada de decis√µes operacionais e administrativas. A proposta √© criar um pipeline de Big Data baseado em uma infraestrutura de nuvem, como a AWS, para realizar an√°lises estat√≠sticas e descritivas de dados armazenados em um Data Lake ou Data Warehouse.

## üìÅ Estrutura de pastas
```
|--> assets\imagens
|--> document
|----> apresenta√ß√£o
|----> outros
|----> documentation.md
|----> README.md
|--> src
| README.md
```

Dentre os arquivos e pastas presentes na raiz do projeto, definem-se:

- <b>assets</b>: Aqui est√£o os arquivos relacionados a parte gr√°fica do projeto, as imagens e v√≠deos que os representam. A subpasta <b>imagens</b> armazena m√≠dias visuais.

- <b>document</b>: Aqui est√£o todos os documentos do projeto. A pasta <b>apresenta√ß√£o</b> cont√©m o arquivos das apresenta√ß√µes realizadas durante as cinco Sprints Reviews. A pasta <b>outros</b> cont√©m documentos complementares como diagramas e regras. Al√©m disso, nesta pasta, h√° um README.md com a organiza√ß√£o das entregas feitas durante as cinco sprints.

- <b>src</b>: Aqui est√£o todos os c√≥digos do projeto.

- <b>README.md</b>: Arquivo que serve como guia e explica√ß√£o geral sobre o projeto.

## üîß Guia de Instala√ß√£o e Configura√ß√£o do Projeto

Este guia foi criado para auxili√°-lo no processo de instala√ß√£o e configura√ß√£o do ambiente necess√°rio para a execu√ß√£o do projeto.

### Pr√©-requisitos

Antes de come√ßar, certifique-se de ter os seguintes softwares instalados no seu computador:

1. Python 3.12 ou superior: Linguagem base do projeto.
2. Docker: Ferramenta para criar e gerenciar cont√™ineres.
3. Poetry: Gerenciador de depend√™ncias Python.
4. Prefect: Framework de orquestra√ß√£o de fluxos de trabalho.

### Passo a Passo de Instala√ß√£o

#### 1. Instale Poetry e Prefect

Execute os seguintes comandos para instalar globalmente o Poetry e o Prefect no Python:

```
pip install poetry
pip install prefect
```

#### 2. Configure o Prefect Cloud

1. Crie uma conta ou fa√ßa login no Prefect Cloud
2. No terminal, execute o comando para se autenticar:

```
prefect cloud login
```

#### 3. Clone o Reposit√≥rio do Projeto

No terminal, acesse o local onde deseja salvar o projeto e execute:

```
git clone https://github.com/Inteli-College/2024-2B-T10-SI08-G04.git
```

#### 4. Navegue at√© o Diret√≥rio do Projeto

Ap√≥s clonar o reposit√≥rio, entre no diret√≥rio principal do projeto:

```
cd 2024-2B-T10-SI08-G04
```

#### 5. Instale as Depend√™ncias do Projeto

Na raiz do reposit√≥rio, instale as depend√™ncias utilizando o Poetry:

```
poetry install
```

#### 6. Configure o Ambiente Virtual

Ative o ambiente virtual gerenciado pelo Poetry:

```
poetry shell
```

Com o ambiente virtual ativo, todos os pacotes instalados estar√£o dispon√≠veis.

### Configura√ß√£o do Docker

#### DataAPP

Para configurar e rodar o DataAPP, siga os passos abaixo:

1. Entre na pasta `dataapp`:

```
cd ./dataapp
```

2. Copie o arquivo `.env.example` e renomeie-o para `.env`:

```
cp .env.example .env
```

3. Edite o arquivo `.env` para preencher as vari√°veis necess√°rias.

4. Construa a imagem Docker para o DataAPP:

```
docker build -t streamlit-app -f Dockerfile .
```

5. Execute o cont√™iner Docker:

```
docker run -p 5000:5000 --env-file .env streamlit-app
```

Ap√≥s esses passos, a aplica√ß√£o estar√° dispon√≠vel em: http://localhost:5000/.

#### ETL

Para rodar os scripts de ETL, siga as etapas:

1. Acesse a pasta `etl_project`:

```
cd ./etl_project
```

2. Copie o arquivo `.env.example` e renomeie-o para `.env`:

```
cp .env.example .env
```

1. Entre da pasta dataapp `cd ./dataapp`
2. Copie o arquivo .env.example
3. Renomeie o arquivo .env.example para .env e preencha-o

#### Backend
Al√©m dos comandos j√° mencionados, para rodar o backend ser√° necess√°rio executar essas a√ß√µes:

4. Executar o comando 
   ```
   docker build -t streamlit-backend -f backend.Dockerfile .
   ```
   com o docker aberto
5. Ap√≥s isso, ser√° necess√°rio executar 
    ```
    docker run -p 7000:7000 --env-file .env streamlit-backend
    ```
    com o docker aberto

Ap√≥s esse passo, √© poss√≠vel acessar a aplica√ß√£o em: `http://172.17.0.1:7000`. Lembre-se de colocar esse endere√ßo no .env antes de executar o docker do frontend.

#### Frontend

4. Executar o comando 
   ```
   docker build -t streamlit-frontend -f frontend.Dockerfile .
   ```
   com o docker aberto
5. Ap√≥s isso, ser√° necess√°rio executar 
    ```
    docker run -p 8501:8501 --env-file .env streamlit-frontend
    ```
    com o docker aberto

4. Construa a imagem Docker para o ETL:

```
docker build -f Dockerfile -t etl_project_image .
```

5. Execute o cont√™iner Docker para o ETL:

```
docker run --rm -it -p 5000:5000 -v [caminho do .prefect]:/root/.prefect --env-file .env etl_project_image
```

- Nota: Substitua `[caminho do .prefect]` pelo caminho da pasta `.prefect` no seu computador.

A aplica√ß√£o estar√° acess√≠vel em: http://127.0.0.1:5000/.

### Execu√ß√£o dos Testes

Para realizar testes no projeto:

1. Certifique-se de que o ambiente virtual est√° ativo.
2. Entre na pasta desejada para testar (`dataapp` ou `etl_project`).
3. Instale as depend√™ncias (caso ainda n√£o tenha feito):

```
poetry install
```

4. Execute os testes utilizando o `pytest`:

```
poetry run pytest -v
```

## Entregas de Sprint

O projeto √© estruturado em 5 sprints, cada uma com entreg√°veis e objetivos espec√≠ficos, que s√£o detalhados abaixo:

#### Sprint 1: Entendimento do projeto

- [Entendimento do neg√≥cio](https://github.com/Inteli-College/2024-2B-T10-SI08-G04/blob/main/document/document.md#2-an%C3%A1lise-de-neg%C3%B3cios)
- [Entendimento de UX](https://github.com/Inteli-College/2024-2B-T10-SI08-G04/blob/main/document/document.md#1-experi%C3%AAncia-do-usu%C3%A1rio)
- [Data Model Canvas](https://github.com/Inteli-College/2024-2B-T10-SI08-G04/blob/main/document/document.md#4-explora%C3%A7%C3%A3o-de-dados)

#### Sprint 2: Protopipa√ß√£o e ingest√£o de dados

- [Prototipa√ß√£o em Baixa fidelidade](https://github.com/Inteli-College/2024-2B-T10-SI08-G04/blob/main/document/document.md#3-arquitetura-e-design-do-sistema)
- [Estrutura de Ingest√£o de Dados](https://github.com/Inteli-College/2024-2B-T10-SI08-G04/blob/main/document/document.md#42-relat%C3%B3rio-etl)

#### Sprint 3: Cubo de dados e An√°lises

- [Cubo de Dados Automatizado](https://github.com/Inteli-College/2024-2B-T10-SI08-G04/blob/main/document/document.md#7-cubo-de-dados-automatizado)
- [Documenta√ß√£o de an√°lise de impacto √©tico](https://github.com/Inteli-College/2024-2B-T10-SI08-G04/blob/main/document/document.md#5-an%C3%A1lise-de-impacto-%C3%A9tico)

#### Sprint 4: DataApp e Infogr√°fico

- [Infogr√°fico](https://github.com/Inteli-College/2024-2B-T10-SI08-G04/blob/main/document/document.md#9-infogr%C3%A1fico)
- [DataApp](https://github.com/Inteli-College/2024-2B-T10-SI08-G04/tree/main/src/dataapp)
- [An√°lise financeira](https://github.com/Inteli-College/2024-2B-T10-SI08-G04/blob/main/document/document.md#10-an%C3%A1lise-financeira-do-projeto)

#### Sprint 5: Entrega final

- [Documenta√ß√£o final](https://github.com/Inteli-College/2024-2B-T10-SI08-G04/blob/main/document/document.md)
- [Apresenta√ß√£o final](https://github.com/Inteli-College/2024-2B-T10-SI08-G04/tree/main/document/apresentacao)
- [DataApp final](https://github.com/Inteli-College/2024-2B-T10-SI08-G04/tree/main/src/dataapp)

## üóÉ Hist√≥rico de lan√ßamentos

* 0.1.0 - 25/10/2024
    * Primeira entrega: Personas, User Storys, Mapa de Jornada do Usu√°rio, TAM, SAM, SOM, Canvas Proposta de Valor, Matriz de Risco e Data Model Canvas.
* 0.2.0 - 08/11/2024
    * Segunda entrega: Wireframe, ETL Bronze, Documenta√ß√£o do ETL e Diagrama UML
* 0.3.0 - 22/11/2024
    * Terceira entrega: An√°lise de Impacto √âtico, Cubo de Dados automatizado e Documenta√ß√£o do Cubo de Dados
* 0.4.0 - 06/12/2024
    * Quarta entrega: Infogr√°fico, DataAPP, An√°lise Financeira e Plano de comunica√ß√£o
* 0.5.0 - 19/12/2024
    * Quinta entrega: Apresenta√ß√£o final, Documenta√ß√£o da solu√ß√£o e Vers√£o final do DataAPP
	
## üìã Licen√ßa/License

<p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><a property="dct:title" rel="cc:attributionURL" href="https://github.com/2023M6T4-Inteli">INTEGRA√á√ÉO, GERENCIAMENTO E AN√ÅLISE DE BIG DATA</a> by <a rel="cc:attributionURL dct:creator" property="cc:attributionName" href="https://github.com/InteliProjects">Inteli</a>, <a rel="cc:attributionURL dct:creator" property="cc:attributionName" href="https://github.com/Inteli-College/2024-2B-T10-SI08-G04">Quartzo</a>: <a href="https://www.linkedin.com/in/celine-souza-1a38aa225?trk=blended-typeahead">Celine Souza</a>, <a href="https://www.linkedin.com/in/joao-pedro-brandao/">Jo√£o Pedro Brand√£o de Moura</a>, <a href="https://www.linkedin.com/in/matheusmeendes/">Matheus Ferreira Mendes</a>, <a href="https://www.linkedin.com/in/paulooctaviodepaula?trk=blended-typeahead">Paulo Octavio De Paula</a>, <a href="https://www.linkedin.com/in/rafaella-bianca-cavalcante/">Rafaella Bianca Cavalcante</a>, <a href="https://www.linkedin.com/in/stefano-parente/">Stefano Tamer Parente</a>, <a href="https://www.linkedin.com/in/yan-m-coutinho/">Yan Mendon√ßa Coutinho</a>, is licensed under <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">Attribution 4.0 International <img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a></p>

## üéì Refer√™ncias


1. CARVALHO, Leandro. Data Product Canvas: A practical framework for building high-performance data products. Medium, 22 jul. 2019. Dispon√≠vel em: https://medium.com/@leandroscarvalho/data-product-canvas-a-practical-framework-for-building-high-performance-data-products-7a1717f79f0. Acesso em: 17 out. 2024.
